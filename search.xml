<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Ubuntu Server 18.04 LTS 上安装Virtual Box 并配置 phpVirtualbox]]></title>
    <url>%2F2019%2F10%2F02%2FUbuntu-Server-18-04-LTS-%E4%B8%8A%E5%AE%89%E8%A3%85Virtual-Box-%E5%B9%B6%E9%85%8D%E7%BD%AE-phpVirtualbox%2F</url>
    <content type="text"><![CDATA[本教程将指导你在 Ubuntu 18.04 LTS 无头服务器上，一步一步地安装 Oracle VirtualBox。同时，本教程也将介绍如何使用 phpVirtualBox 去管理安装在无头服务器上的 VirtualBox 实例。phpVirtualBox 是 VirtualBox 的一个基于 Web 的前端工具。这个教程也可以工作在 Debian 和其它 Ubuntu 衍生版本上，如 Linux Mint。现在，我们开始。原文地址:https://www.ostechnix.com/install-oracle-virtualbox-ubuntu-16-04-headless-server/ 前提条件在安装 Oracle VirtualBox 之前，我们的 Ubuntu 18.04 LTS 服务器上需要满足如下的前提条件。首先，逐个运行如下的命令来更新 Ubuntu 服务器。 123sudo apt updatesudo apt upgradesudo apt dist-upgrade 接下来，安装如下的必需的包 1sudo apt install build-essential dkms unzip wget 安装完成所有的更新和必需的包之后，重启动 Ubuntu 服务器。 1sudo reboot 安装 VirtualBox添加 Oracle VirtualBox 官方仓库。为此你需要去编辑 /etc/apt/sources.list 文件： 1sudo nano /etc/apt/sources.list 添加下列的行 1deb http://download.virtualbox.org/virtualbox/debian bionic contrib 然后，运行下列的命令去添加 Oracle 公钥： 1wget -q https://www.virtualbox.org/download/oracle_vbox_2016.asc -O- | sudo apt-key add - 接下来，使用如下的命令去更新软件源 1sudo apt update 最后，使用如下的命令去安装最新版本的 Oracle VirtualBox 1sudo apt install virtualbox-5.2 添加用户到 VirtualBox 组 我们需要去创建并添加我们的系统用户到 vboxusers 组中。你也可以单独创建用户，然后将它分配到 vboxusers 组中，也可以使用已有的用户。我不想去创建新用户，因此，我添加已存在的用户到这个组中。请注意，如果你为 virtualbox 使用一个单独的用户，那么你必须注销当前用户，并使用那个特定的用户去登入，来完成剩余的步骤。 我使用的是我的用户名 sk，因此，我运行如下的命令将它添加到 vboxusers 组中。 1sudo usermod -aG vboxusers sk 现在，运行如下的命令去检查 virtualbox 内核模块是否已加载。 1sudo systemctl status vboxdrv 如果 virtualbox 模块没有启动，运行如下的命令去启动它。 1sudo /etc/init.d/vboxdrv setup 很好！我们已经成功安装了 VirtualBox 并启动了 virtualbox 模块。现在，我们继续来安装 Oracle VirtualBox 的扩展包。 安装 VirtualBox 扩展包 VirtualBox 扩展包为 VirtualBox 访客系统提供了如下的功能。 虚拟的 USB 2.0 (EHCI) 驱动 VirtualBox 远程桌面协议（VRDP）支持 宿主机网络摄像头直通 Intel PXE 引导 ROM 对 Linux 宿主机上的 PCI 直通提供支持 从这里为 VirtualBox 5.2.x 下载最新版的扩展包。 1wget https://download.virtualbox.org/virtualbox/5.2.14/Oracle_VM_VirtualBox_Extension_Pack-5.2.14.vbox-extpack 使用如下的命令去安装扩展包： 1sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-5.2.14.vbox-extpack 恭喜！我们已经成功地在 Ubuntu 18.04 LTS 服务器上安装了 Oracle VirtualBox 的扩展包。现在已经可以去部署虚拟机了。参考 virtualbox 官方指南，在命令行中开始创建和管理虚拟机。 然而，并不是每个人都擅长使用命令行。有些人可能希望在图形界面中去创建和使用虚拟机。不用担心！下面我们为你带来非常好用的 phpVirtualBox 工具！ 关于 phpVirtualBoxphpVirtualBox 是一个免费的、基于 web 的 Oracle VirtualBox 后端。它是使用 PHP 开发的。用 phpVirtualBox 我们可以通过 web 浏览器从网络上的任意一个系统上，很轻松地创建、删除、管理、和执行虚拟机。 在 Ubuntu 18.04 LTS 上安装 phpVirtualBox由于它是基于 web 的工具，我们需要安装 Apache web 服务器、PHP 和一些 php 模块。 为此，运行如下命令： 1sudo apt install apache2 php php-mysql libapache2-mod-php php-soap php-xml 然后，从 下载页面 上下载 phpVirtualBox 5.2.x 版。请注意，由于我们已经安装了 VirtualBox 5.2 版，因此，同样的我们必须去安装 phpVirtualBox 的 5.2 版本。 运行如下的命令去下载它： 1wget https://github.com/phpvirtualbox/phpvirtualbox/archive/5.2-0.zip 使用如下命令解压下载的安装包： 1unzip 5.2-0.zip 这个命令将解压 5.2.0.zip 文件的内容到一个名为 phpvirtualbox-5.2-0 的文件夹中。现在，复制或移动这个文件夹的内容到你的 apache web 服务器的根文件夹中。 1sudo mv phpvirtualbox-5.2-0/ /var/www/html/phpvirtualbox 给 phpvirtualbox 文件夹分配适当的权限。 1$ sudo chmod 777 /var/www/html/phpvirtualbox/ 接下来，我们开始配置 phpVirtualBox。 像下面这样复制示例配置文件。 1sudo cp /var/www/html/phpvirtualbox/config.php-example /var/www/html/phpvirtualbox/config.php 编辑 phpVirtualBox 的 config.php 文件： 1sudo nano /var/www/html/phpvirtualbox/config.php 找到下列行，并且用你的系统用户名和密码去替换它（就是前面的“添加用户到 VirtualBox 组中”节中使用的用户名）。 在我的案例中，我的 Ubuntu 系统用户名是 sk ，它的密码是 ubuntu。 12var $username = 'sk';var $password = 'ubuntu'; 保存并关闭这个文件。接下来，创建一个名为 /etc/default/virtualbox 的新文件： 1sudo nano /etc/default/virtualbox 添加下列行。用你自己的系统用户替换 sk。 1VBOXWEB_USER=sk 最后，重引导你的系统或重启下列服务去完成整个配置工作。 123sudo systemctl restart vboxweb-servicesudo systemctl restart vboxdrvsudo systemctl restart apache2 调整防火墙允许连接 Apache web 服务器 如果你在 Ubuntu 18.04 LTS 上启用了 UFW，那么在默认情况下，apache web 服务器是不能被任何远程系统访问的。你必须通过下列的步骤让 http 和 https 流量允许通过 UFW。 首先，我们使用如下的命令来查看在策略中已经安装了哪些应用： 123456sudo ufw app listAvailable applications:ApacheApache FullApache SecureOpenSSH 正如你所见，Apache 和 OpenSSH 应该已经在 UFW 的策略文件中安装了。 如果你在策略中看到的是 Apache Full，说明它允许流量到达 80 和 443 端口： 1234567sudo ufw app info "Apache FullProfile: Apache FullTitle: Web Server (HTTP,HTTPS)Description: Apache v2 is the next generation of the omnipresent Apache webserver.Ports:80,443/tcp 现在，运行如下的命令去启用这个策略中的 HTTP 和 HTTPS 的入站流量： 123sudo ufw allow in "Apache Full"Rules updatedRules updated (v6) 如果你希望允许 https 流量，但是仅是 http (80) 的流量，运行如下的命令： 1sudo ufw app info "Apache 访问 phpVirtualBox 的 Web 控制台 现在，用任意一台远程系统的 web 浏览器来访问。在地址栏中，输入：http://IP-address-of-virtualbox-headless-server/phpvirtualbox。在我的案例中，我导航到这个链接 – http://192.168.225.22/phpvirtualbox。你将看到如下的屏幕输出。输入 phpVirtualBox 管理员用户凭据。phpVirtualBox 的默认管理员用户名和密码是 admin / admin。 恭喜！你现在已经进入了 phpVirtualBox 管理面板了。 现在，你可以从 phpvirtualbox 的管理面板上，开始去创建你的 VM 了。正如我在前面提到的，你可以从同一网络上的任意一台系统上访问 phpVirtualBox 了，而所需要的仅仅是一个 web 浏览器和 phpVirtualBox 的用户名和密码。 如果在你的宿主机系统（不是访客机）的 BIOS 中没有启用虚拟化支持，phpVirtualBox 将只允许你去创建 32 位的访客系统。要安装 64 位的访客系统，你必须在你的宿主机的 BIOS 中启用虚拟化支持。在你的宿主机的 BIOS 中你可以找到一些类似于 “virtualization” 或 “hypervisor” 字眼的选项，然后确保它是启用的。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 18.04上安装docker和docker-compose]]></title>
    <url>%2F2019%2F09%2F28%2Fubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker%E5%92%8Cdocker-compose%2F</url>
    <content type="text"><![CDATA[- 安装docker更新包列表1sudo apt update 安装必备软件包1sudo apt install apt-transport-https ca-certificates curl software-properties-common 将官方Docker存储库的GPG密钥添加到系统1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 将Docker存储库添加到APT源1sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable" 再次更新包列表1sudo apt update 查看缓存apt，确保从Docker repo而不是默认的Ubuntu 16.04 repo安装123456789apt-cache policy docker-ceapt-cache策略docker-ce的输出docker-ce: Installed: (none) Candidate: 18.03.1~ce~3-0~ubuntu Version table: 18.03.1~ce~3-0~ubuntu 500 500 https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages 最后，安装Docker1sudo apt install docker-ce 安装Docker Compose下载1sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 设置权限1sudo chmod +x /usr/local/bin/docker-compose 验证1docker-compose --version]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Calibre制作带目录的电子书]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Calibre%E5%88%B6%E4%BD%9C%E5%B8%A6%E7%9B%AE%E5%BD%95%E7%9A%84%E7%94%B5%E5%AD%90%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[原文出处：http://alwa.info 1. 导言本文主要讲如何使用Calibre通过txt格式的电子书，制作成带目录的mobi或者epub格式的电子书。 主要准备工作包括，你需要有Calibre，并且懂得一点正则表达式 2. 安装Calibre下载链接 3. 制作目录下载一个txt格式的电子书。我以《陆小凤传奇》为例（版权问题就不放下载链接了）。 使用Atom打开（当然用Sublime和Word也是一样的，大文件别用Atom打开，会炸）。找到替换，然后打开 正则表达式匹配选项（regular expression）。 首先这本书有五部： 金鹏王朝（又名陆小凤传奇） 绣花大盗 决战前后 银钩赌坊 幽灵山庄 所以先匹配第几部作为目录第一级。目录第一级在文本里用#表示。 搜寻框填写 1(第 [一二三四五六七八九] 部) 替换框填写 1# $1 原本是 1第 一 部 金鹏王朝 变成了 1# 第 一 部 金鹏王朝 然后就是匹配各个章节，作为目录第二级。目录第二级在文本里用##表示。 搜寻框填写。因为出现 12第 一 回 有四条眉毛的人第二回 丹凤公主 两种不同格式，所以需要匹配那个多的空格。超过百回的一样的原理，多一个百。 1(第)[ ]*([一二三四五六七八九][十]*[一二三四五六七八九]*)[ ]*(回) 替换框填写 1## $1$2$3 原本是 12第 一 回 有四条眉毛的人第二回 丹凤公主 变成了 12## 第一回 有四条眉毛的人## 第二回 丹凤公主 因为每本都有一个尾声，再匹配一下尾声就行。 1尾 声 替换为 1## 尾 声 这样就已经完成制作电子书目录的工作，后面就是转换书籍格式。把修改好的电子书拖进Calibre书库里面。 转换格式原本在Calibre里是我们修改好的txt电子书，现在我们需要把电子书转换成mobi格式。epub等其他格式后面用mobi可以直接进行转换。 选择这本书，然后按选项栏里的转换书籍。可以看到最左边是书籍本身格式txt,把右边格式输出格式改成mobi。当然你可以修改图书基本属性，以及封面等。如图所示： 然后选择内容目录，调整为如图所示。主要是一级目录和二级目录表达式：//h:h1。这也是为了对应之前我们所说的#和##。注意上面的最大章节数可能需要修改。完成后点击确定。 成书现在就可以打开书籍，发现目录已经生成。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[禁止windows生成thumbs.db]]></title>
    <url>%2F2019%2F09%2F28%2F%E7%A6%81%E6%AD%A2windows%E7%94%9F%E6%88%90thumbs-db%2F</url>
    <content type="text"><![CDATA[以windows10为例，如何禁止windows生成thumbs.db 1、按下 Win+R 打开“运行”，输入：gpedit.msc 回车; 2、在打开的组策略窗口中，依次点开： 用户配置&gt;管理模版&gt;Windows 组件找到右侧的“文件资料管理器”，双击打开; 3、找到并双击打开“关闭隐藏的thumbs.db文件中的缩略图缓存”;4、勾选“已启用”并“应用”设置，下次开机之后thumbs.db就不见了。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync命令比对文件及增量同步]]></title>
    <url>%2F2019%2F09%2F28%2Frsync%E5%91%BD%E4%BB%A4%E6%AF%94%E5%AF%B9%E6%96%87%E4%BB%B6%E5%8F%8A%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[A fast,versatile,remote (and local) file-copying tool. rsync基于ssh协议实现高效率远程或本地文件复制，传输速度比scp快。复制文件时会比对本地文件与远程主机的文件，仅复制有差异的文件。 常用选项： 12345678910111213141516171819202122-q,--quiet：suppress non-error messages 静默模式-v,--verbose：increase verbosity-a,--archive：archive mode; equals -rlptgoD (no -H,-A,-X) 归档模式，相当于-rlptgoD,不包括(no -H,-A,-X);最常用的参数-H,--hard-links：preserve hard links 保留硬链接-A,--acls：preserve ACLs (implies --perms) 保留ACL权限-X,--xattrs：preserve extended attributes 保留扩展属性-c, --checksum：skip based on checksum, not mod-time &amp; size-r,--recursive：recurse into directories 递归-l,--links：copy symlinks as symlinks 保留软链接,而不跟踪原文件-p,--perms：preserve permissions 保留权限-t,--times：preserve modification times 保留mtime-g,--group：preserve group 保留属组-o,--owner：preserve owner (super-user only) 保留属主-D：same as --devices,--specials 保留设备文件和特殊文件--devices：preserve device files (super-user only)--specials：preserve special files-z,--compress：compress file data during the transfer 输过程中压缩文件数据-n, --dry-run：perform a trial run with no changes made 干跑测试-u,--update：skip files that are newer on the receiver 增量同步，跳过比本地较新的文件--delete：delete extraneous files from destination dirs 删除目标目录多余文件--progress：show progress during transfer 显示传输进度 本地复制 1rsync -av ansible_auto/public/uy-s-192-v01.cfg objects/ansible_auto/public/uy-s-192-v01.cfg 比对文件 12cd /usr/local/nagios/etc/rsync -acvn ansible_auto/ objects/ansible_auto/ &gt; diff 增量同步（合并目录文件，最终与目标目录一致） 1rsync -avzu --progress /opt/* devops@11.0.10.8:/opt/ 删除同步（删除目标目录多余文件，最终与源目录一致） 1rsync -avzu --delete --progress /opt/* devops@11.0.10.8:/opt/ 另外，可以设置计划任务实时同步和备份文件 12crontab -e*/1 * * * * rsync -avzu /opt/media/* 192.168.201.123:/opt/media]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 mergerfs 合并多块硬盘的剩余空间]]></title>
    <url>%2F2019%2F09%2F28%2F%E4%BD%BF%E7%94%A8-mergerfs-%E5%90%88%E5%B9%B6%E5%A4%9A%E5%9D%97%E7%A1%AC%E7%9B%98%E7%9A%84%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[两年前，我买了一台 HP Gen8 微型服务器，其功能之一是作为网络存储。当时它只接了一块 SSD 作为系统盘和一块 2 TB HDD 作为存储盘。随着存储文件的增多，我又先后增加了两块 4 TB HDD，现在它已经接了共计 10 TB 的存储空间。我觉得有必要分享一下我用来将这些硬盘的空间合并在一起的工具——mergerfs。 | 原文出处:https://wzyboy.im/post/1148.html 一、网络存储之硬盘困境在讲工具之前，我有必要先说明一下我目前的存储方案。 我的 Gen8 没有直接装通用操作系统，而是先通过 ESXi 实现了虚拟化，再将存储盘通过 RDM 的方式完整地映射给其中的一台虚拟机（Arch Linux）。在 Arch Linux 里运行了 Samba, NFS, aria2 RPC, Transmission daemon, BorgBackup 等服务，供局域网电脑存取文件、远程下载，以及备份。 我在存储盘里的东西分为两类：一类是多份备份中的一份BorgBackup；另一类是从互联网上下载的可再生资源。前者本身有冗余，后者丢了不心疼。出于以上考虑，为了硬盘空间利用率的最大化，我并没有采用 RAID 1 或 RAID 5 之类的冗余存储的方案，而是采用了 JBOD 方案——Just Bunch of Disks。 不使用 RAID 做冗余还有一个原因：我希望这些硬盘从 Gen8 上拔下来之后接到别的电脑上我能直接读取它们。 当我的第一块存储盘快要装满的时候，我买了第二块盘，这时候就面临了一个问题：如何把两块硬盘的空间合并？考虑到我已经在运行的那些服务，我自然不想再增加一个额外的挂载点。我曾考虑过三个硬盘空间合并方案： RAID 0。与 RAID 1 或 RAID 5 不同，RAID 0 是对多块相同容量的硬盘进行平行读写，从而提升性能，其额外效果就是硬盘空间也被合并了。但这种方案非常危险：多块硬盘中的任意一块挂了，所有的数据都将无法读取。这个方案不行。 LVM。相比 RAID 0 的原理，LVM 只是将空间连接起来了，而没有平行读写，所以多块硬盘中的一块挂了，也只是丢了那一块的数据。但创建过 LVM PV 的硬盘，在别的机器上读取起来比较麻烦，所以这个方案我也不喜欢。 MooseFS。相对前两种方案，由于它在 FUSE 层面实现，所以更灵活一些，甚至可以通过网络，把没有挂在 Gen8 上的硬盘也纳入存储空间。但这个方案和 LVM 一样，协作性不强，硬盘在别的机器上只能看到一堆数据碎块文件，因此也被我否决了。 以上三种方案还有一个问题：我需要把硬盘里现有的数据全部倒出来再倒进去……我需要的是能将文件分散存储到多块硬盘，同时又不改变文件形态的方案。 二、mhddfs 与 mergerfs早有人遇到过像我一样的困境，于是他开发了 mhddfs。在用了它一段时间之后，我又发现了一个更好的实现 mergerfs。两者的思路类似，但后者比前者功能更丰富、更安全、更稳定。本文以后者为例说明。 mergerfs 的思路是用 FUSE 实现一个新的文件系统，它的下层存储并不是直接的块设备，而是别的已经挂载的文件系统。mergerfs 接收到读写请求时，它会根据约定好的策略，从下层文件系统中读取文件，或是将数据写入下层文件系统。mergerfs 所呈现的文件系统，容量是所有下层文件系统之和，而内容则是所有下层文件系统的合并。 引用 mergerfs README 里的 ASCII art： 123456789101112131415161718A + B = C/disk1 /disk2 /merged| | |+-- /dir1 +-- /dir1 +-- /dir1| | | | | || +-- file1 | +-- file2 | +-- file1| | +-- file3 | +-- file2+-- /dir2 | | +-- file3| | +-- /dir3 || +-- file4 | +-- /dir2| +-- file5 | |+-- file6 | +-- file4 | +-- /dir3 | | | +-- file5 | +-- file6 如图所示，/merged 是 mergerfs 的挂载点，其下层两个文件系统的挂载点是 /disk1 和 /disk2。 这样一个文件系统完全符合我的需求：读写文件时能获得合并空间的优势，而当硬盘损坏或是想要直接读取硬盘里的数据的时候又可以单独把硬盘拆出来读取。而且我不用把现有的数据倒腾来倒腾去了，无痛迁移！ 三、mergerfs 的安装与配置mergerfs 的作者非常勤奋，每个版本都会为 RHEL / CentOS, Fedora, Debian, Ubuntu 不同发行版的不同版本、不同架构组合打包 30 多个 rpm 和 deb 安装包，其中包括了 ARM 甚至 PowerPC 架构，方便使用 Raspberry Pi 或是老 Mac 作为网络存储设备的用户。Arch Linux 用户则可以通过 AUR 安装。 安装之后通过编辑 /etc/fstab 来挂载 mergerfs。我使用的 fstab 如下： 1234/dev/sdb1 /media/disk1 ext4 defaults,noauto 0 0/dev/sdc1 /media/disk2 ext4 defaults,noauto 0 0/dev/sdd1 /media/disk3 ext4 defaults,noauto 0 0/media/disk1:/media/disk2:/media/disk3 /media/vdisk fuse.mergerfs defaults,noauto,allow_other,use_ino,minfreespace=100G,ignorepponrename=true 0 0 前三行是三块存储盘的普通挂载，第四行是 mergerfs 的条目，它的挂载源是前三块盘的的挂载点，用冒号分隔。最后一列的参数说明： defaults: 开启以下 FUSE 参数以提升性能：atomic_o_trunc, auto_cache, big_writes, default_permissions, splice_move, splice_read, splice_write； noauto: 禁止开机自动挂载。意外关机重启之后我可能需要手动检查文件系统后再挂载，所以我不希望它自动挂载； allow_other: 允许挂载者以外的用户访问 FUSE。你可能需要编辑 /etc/fuse.conf 来允许这一选项； use_ino: 使用 mergerfs 而不是 libfuse 提供的 inode，使硬链接的文件 inode 一致； minfreespace=100G: 选择往哪个下层文件系统写文件时，跳过剩余空间低于 100G 的文件系统； ignorepponrename=true: 重命名文件时，不再遵守路径保留原则，见下一节详解。 写完 fstab 之后就可以让 mergerfs 跑起来了： 1mount /media/disk1 &amp;&amp; mount /media/disk2 &amp;&amp; mount /media/disk3 &amp;&amp; mount /media/vdisk 效果： 12345Filesystem Size Used Avail Use% Mounted on/dev/sdb1 1.8T 1.7T 179G 91% /media/disk1/dev/sdc1 3.6T 3.4T 215G 95% /media/disk2/dev/sdd1 3.6T 89M 3.4T 1% /media/disk31:2:3 9.0T 5.0T 3.8T 57% /media/vdisk disk3 是我今天刚装上的，所以它还是空的。 四、mergerfs 的读写策略如果多块硬盘里同名的目录或文件，从哪儿读？往哪儿写？如果多块硬盘都有足够的剩余空间，在哪块硬盘创建新文件？mergerfs 对 FUSE 的不同操作有着不同的读写策略。默认的策略是： action 类别：对于 chmod, chown 等改变文件或目录属性的操作，mergerfs 检索所有下层文件系统，确保所有文件或目录都得到更改； search 类别：对于 open, getattr 等读取文件或目录的操作，mergerfs 按挂载源列表的顺序检索下层文件系统，返回第一个找到结果； create 类别：对于 create, mkdir 等创建文件或目录的操作，mergerfs 优先选择相对路径已经存在的下层文件系统中剩余空间最大的那个作为写入目标。 前两条很好理解，最后一条比较拗口。举例来说是这样： disk1 剩余 100 GiB 空间，有 /dir1 目录； disk2 剩余 200 GiB 空间，有 /dir2 目录； disk3 剩余 300 GiB 空间，有 /dir3 目录； mergerfs 将这三块硬盘的文件系统合并成一个，可以同时看到 /dir1, /dir2, /dir3 三个目录。 这时在 mergerfs 对于上层文件系统写入一个 150 GiB 的文件到 /dir2/foo.bin 位置，按照默认的策略，mergerfs 会选择 disk2 写入。因为：disk1 剩余空间不足（小于 minfreespace 或是只读文件系统也会被跳过选择），而虽然 disk3 比 disk2 剩余空间更多，但因为 disk2 已经有 /dir2 目录了，所以 mergerfs 会优先选择写入 disk2 而不是 disk3。 这个策略的意义在于，当下层文件系统的剩余空间差不多时，你的文件不会被分散开。比如你正在将你的相机图片文件夹复制到 mergerfs 里，一个文件夹里有 999 张图片，第一张图片的落点也将决定接下来 998 张文件的落点，而不会因为下层文件系统剩余空间的交替变化而一会儿落到这个文件系统，一会儿落到那个文件系统。最终下层文件系统会被平衡地使用，但相同目录的文件会尽可能地在同一个文件系统里，这非常棒。 但这个策略一直有一个痛点让我难受了很久：移动文件。比如 2016 年份的文件位于 disk1，而 2017 年份的文件因为 disk1 已经满了写到 disk2 来了，在 2018 年的时候我想把三年的文件都归到一个新目录里。此时 2016 年的文件可以瞬间完成，2017 年的文件则由于上述策略会优先选择 disk1，于是就从瞬间完成变成了缓慢的跨盘移动，当这些文件数量巨大的时候，已经开始的传输我又不敢贸然中止……这样的坑我在整理文件时掉过很多次。终于，mergerfs 2.23.0 版本新增了 ignorepponrename 选项，使得在重命名文件的时候，忽略路径保留规则，避免了简单的文件整理操作变成痛苦的跨盘移动的悲剧。 如果 mergerfs 的默认读写策略不适用于你的应用场景，可以通过挂载参数选用别的策略。 本文地址：https://wzyboy.im/post/1148.html 读者来信：有关 ZFS2018-02-11 读者 Rmrf99 &#x72;&#x2e;&#x2e;&#x2e;&#x40;&#x70;&#x72;&#x6f;&#x74;&#x6f;&#x6e;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109; 来信推荐了 ZFS。Rmrf99 在自己的 Ubuntu 工作站上使用 ZFS 作为存储方案。我没有用过 Solaris，对 ZFS on Linux 也不是很了解。在 Rmrf99 的推荐下，我在 Ubuntu 虚拟机中尝试了 ZFS。ZFS 将 RAID / LVM 中的「卷」的概念与文件系统概念结合了：使用块设备直接创建 ZFS pool，而 pool 的更小单位就直接是文件系统了，调整大小、快照、缓存、加密、配额等都很方便，不再需要像 LVM 像俄罗斯套娃那样一层一层地操作。 然而，在我的使用场景下，ZFS 相比 mergerfs 有两点不适合我的地方： 有时我需要高速读取/写入大量数据，我目前的做法是直接将一块存储盘从 Gen8 上拔下来，使用 SATA-USB 转换器将其连接至计算机，而 ZFS pool 中的某个成员不能脱离 pool 单独工作，你也不能将一块已经加入 pool 的成员从 pool 中移除（除非拆毁 pool 并重建）； 相比 Ubuntu，目前 Arch Linux 对 ZFS on Linux 的支持不够完善，使用和维护成本较高，与 ZFS 的 zero administration 理念相违背。 此外，对于需要跨平台协作的用户来说，mergerfs 可以将不同文件系统的分区拼成一个，使 Ext4 与 NTFS 和谐共处，而 ZFS 在可预见的未来没有可用的 Windows 支持。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目录级别的冗余存储：SnapRAID]]></title>
    <url>%2F2019%2F09%2F28%2F%E7%9B%AE%E5%BD%95%E7%BA%A7%E5%88%AB%E7%9A%84%E5%86%97%E4%BD%99%E5%AD%98%E5%82%A8%EF%BC%9ASnapRAID%2F</url>
    <content type="text"><![CDATA[在数据存储领域，「备份」和「冗余」是两种常见的数据保护策略。两种策略各有不同的使用场景，对于重要数据，两者一起使用自然是最好了。本文介绍使用 SnapRAID 实现灵活的数据冗余存储。 原文地址： https://wzyboy.im/post/1186.html 一、神奇的奇偶校验小时候一直觉得 WinRAR 的「恢复卷」功能非常神奇。比如有一个 100 MiB 的压缩文件分成 10 个分卷，每个 10 MiB，创建者又创建了 3 个恢复卷，每个也是 10 MiB。当复制、分发这些卷的时候，如果因为数据传输、磁盘存储等各种原因，导致 10 个数据卷中有部分文件损坏或丢失，只要损坏或丢失的数据卷的数量小于等于恢复卷的数量，就可以用对应数量的恢复卷来修复压缩包。 小时候不理解为什么丢失一部分数据之后可以用现有的数据重新算出来，现在明白了，最简单的实现便是奇偶校验。 奇偶校验常见于数据传输中。比如 1 个字节（byte）由 8 个比特（bit）组成，但双方约定：只用 7 bit 来存储数据，剩下 1 bit 作为校验位（parity bit）。校验规则是：如果前面 7 bit 里 1 的数量为奇数（1, 3, 5, 7），则 parity bit 为 1；如果前面 7 bit 里 1 的数量为偶数（0, 2, 4, 6），则 parity bit 为 0。这样最终这个 byte 里 1 的数量一定是偶数，如果接收方发现 1 的数量不是偶数，那就说明出错了，一定是在传输过程中发生了比特翻转（bit flip），即本来是 0 的变成了 1，或本来是 1 的变成了 0。当然，如果这个 byte 在传输过程中发生了偶数个 bit flip，那校验倒也恰好能通过，但由于同一 byte 里有大于一个 bit flip 的概率非常低，所以奇偶校验在实际应用中还是非常简单有效的。 然而，上述奇偶校验只能知道「出错了」，但是无法知道「哪里出错了」，也无法修复出错的部分。但是在存储的时候，人们往往是知道哪里出错的。想像一下，如果上述 8 bit 不是存在同一 byte 里而是分散在 8 块磁盘上，这时候某一块磁盘突然挂了，你是明确地知道「哪里出错了」的（磁盘不转了），因此你根据其他 7 块磁盘里的 bit 值，来反推出坏掉的磁盘里存储的是 0 还是 1（把 1 的总数凑成偶数即可），也就是说，你可以利用 7 块健在的磁盘上的数据，修复坏掉的磁盘上的数据。 显然地，如果 8 块磁盘同时坏了 2 块或以上，那就有 00, 01, 10, 11 四种可能了，只有一个奇偶校验位的情况下是修复不了的。幸运的是，计算机科学家和数学家们早就研究出了其他更高级的冗余算法，可以使一组数据有两个或两个以上的校验位，用来在已知「哪里出错了」的情况下，修复出错的部分。SnapRAID 所用的冗余算法，用 N 个存储器用来存储数据，同时用 P 个存储器用来存放校验数据（P ≤ 6, P ≤ N_），在总数 _P + N 的存储器中，任意坏掉 X 个，只要 _X ≤ P_，就能用剩下存储器里的数据计算出坏掉的存储器里的数据。 这便是冗余存储的理论基础。 二、备份与冗余存储虽说「备份」和「冗余」两大数据保护策略有各自的使用场景，冗余并不能取代备份，但如果要将这两者进行比较的话，冗余相比备份最大的优点，是可以相对节省存储空间。回顾上一节里提到的 7 + 1 块磁盘的场景，假设每块磁盘是 1 TB，则有效存储空间是 7 TB，剩下 1 TB 是校验数据。在磁盘使用过程中，任意一块磁盘坏掉，你都可以重新买一块新的替换磁盘，然后把坏掉磁盘的内容完整地推算出来，相当于你用 1 TB 的空间，换取了 7 TB 数据的「相对安全」（仅就对抗硬件故障而言），比完整备份 7 TB 数据省了很多空间。 然而，实际生产生活中，7 + 1 这样的组合风险比较高，因为同时开始使用的磁盘，很可能一起坏掉，一旦有两块磁盘同时坏掉，就会有数据无法被修复了。悲剧往往是这样发生的：一组磁盘里坏了一块，然后换了块新的上去，开始根据旧磁盘的数据推算出坏掉磁盘里原有的数据并写入新磁盘，由于这个推算过程需要将所有旧磁盘里的数据全部读一遍（视磁盘大小，这个过程可能会持续一两天），大量的读取操作成了最后一根稻草，还没等新磁盘填满，又一块旧磁盘挂了。 根据存储及备份提供商 BackBlaze 公开的信息，他们使用的是 13 + 2 的组合，即 15 块磁盘一组，最多能同时坏 2 块磁盘而不丢数据。 三、RAID 与 ZFS在数据中心里，冗余存储最常见实现是 RAID。使用带冗余的 RAID 级别，如 RAID 5 和 RAID 6，可以在空间利用率和容错性之间达到一个平衡。存储服务器一般会安装硬件 RAID 卡，实现对操作系统透明的 RAID（操作系统看到的就是一个已经带冗余存储的磁盘，并不用关心下面是几块磁盘、怎么实现的）。在 GNU/Linux 中也可以使用 mdadm 工具实现软件 RAID，无需专门的硬件即可实现冗余存储。 在《使用 mergerfs 合并多块硬盘的剩余空间》一文的「读者来信」一节，有读者推荐了 ZFS。这套来自 Sun 的存储方案也可以实现类似 RAID 的功能，包括冗余存储。 然而，使用 RAID 和 ZFS 进行冗余存储都存在一个问题：data lock-in。即，要在已有数据的磁盘上使用 RAID / ZFS，需要把数据先导出，将磁盘清空，然后重新导入数据，并且你想要将某块磁盘脱离 RAID / ZFS 单独读写里面的数据也非常麻烦（如果不是不可能）。 这在数据中心看来也许不是什么问题，但是我希望能有一个更加灵活、自由的冗余存储方案。 四、似 RAID 而非 RAID 的 SnapRAIDSnapRAID 是一个目录级别的冗余存储方案，它与 RAID 的原理有相似的地方，但它并不是 RAID。SnapRAID 与 RAID 的主要区别有： SnapRAID 不会对数据进行条带化存储。RAID 通常会使用数据条带化，一个文件可能会被分散存储到多块磁盘上，这样的优点是读取的时候可以加速（多块磁盘同时读取），但条带化也是上节所说的 data lock-in 的根源——你不能拆出一块盘单独读写。 SnapRAID 是工作于文件系统之上的。RAID 工作于文件系统之下，直接对磁盘区块进行操作，用磁盘区块上的比特计算校验数据，而 SnapRAID 是通过读取文件系统里的文件之后再进行计算的。 SnapRAID 是非实时的。RAID 每时每刻都在工作，磁盘区块上的数据一旦发生变更就会重新计算校验数据，而 SnapRAID 可以在用户选择的时间进行重新计算。 SnapRAID 相比 RAID 的优点主要有： 数据独立。不需要对磁盘做特殊处理，可以直接将已有数据的磁盘（甚至可以是不同文件系统的）加入 SnapRAID，SnapRAID 也不会改变这些已有的数据；一个文件不会被分散到多个磁盘，随时可以拆下来一块磁盘正常读写里面的数据；当磁盘阵列收到文件读写请求时，也只需要一块磁盘响应，而不是所有的磁盘全部从待机状态启动，开始寻道。 抗灾能力。当磁盘列阵中同时损坏的磁盘数量超出预期而无法修复数据时，SnapRAID 的抗灾能力更强。例如：在 3 + 1 的 RAID 场景下，坏一块没事，如果同时坏了两块，所有的磁盘上的数据都将无法读取（因为条带化）；但如果是 3 + 1 的 SnapRAID，就算同时坏两块，剩下两块里的数据依然可以正常读取。 配置灵活。标准的 RAID 等级中，RAID 5 最多承受 1 块磁盘同时损坏，RAID 6 最多承受 2 块磁盘同时损坏；而 SnapRAID 可以配置 1 到 6 块校验盘，最多承载 6 块磁盘同时损坏，因此可以组建更大的磁盘阵列而不提升风险（维持数据盘与校验盘的比例不变）。更重要的是，无论是增加还是减少磁盘，SnapRAID 都可以无痛完成，无需清空磁盘数据。 恢复误删文件。由于 RAID 是实时计算校验数据的，当文件被删除时，这一改动立刻就会被同步到校验数据里；而 SnapRAID 在用户请求的时候才进行同步，因此用户可以用 SnapRAID 从校验数据重新构建被误删除的文件。当然了，更可靠、更持久的的误删除防护还是应该用增量备份来完成。 空间利用率高。在磁盘阵列中，校验盘的大小应大于等于数据盘中最大的那块。使用 SnapRAID 时，你可以「超售」。比如数据盘是 6 TB 的但是只装了一半（3 TB），你把 4 TB 的磁盘作为校验盘也是可以的（因为此时校验数据最多只有 3 TB），只要在校验文件膨胀到接近 4 TB 的时候将校验文件挪到更大的磁盘里即可。同样的，校验盘里未被校验文件填满的剩余空间也可以用来存储一些「丢了也无所谓」的不重要数据。此外，由于 SnapRAID 工作于文件系统之上，你可以选择性地排除掉一些不想做冗余的目录和文件，以节省空间。 五、SnapRAID 的配置与使用SnapRAID 提供了 Windows 版本的二进制文件下载；GNU/Linux、macOS，以及各种 Unix-like 可以从源码编译或从软件仓库中安装。SnapRAID 的配置文件简洁且注释详尽，读注释就能明白怎么配了。 目前我的 Gen8 里有三块 SATA 磁盘，容量分别是 2 TB, 4 TB, 4 TB。前两块服役多年，几乎满了，第三块是新买的，还是空的，我想把第三块磁盘作为校验盘。我的相关配置是这样的： 123456789101112131415161718192021222324252627282930313233343536373839# 校验文件的位置# 显然，校验文件不能放在数据盘上，否则就没有意义了parity /media/disk3/snapraid.parity# 如需添加更多的校验文件则继续添加# 最多是 6 份校验，承受磁盘磁盘阵列中最多同时坏掉 6 块盘的情况#2-parity /media/disk4/snapraid.2-parity#3-parity /media/disk5/snapraid.3-parity# 重要的索引文件，建议保存多份（内容是一样的）# 我在系统盘（SSD）上存了一份，然后在三块磁盘上都各存一份# 系统盘上的这份同时又会被 BorgBackup 异地备份content /home/snapraid/snapraid.contentcontent /media/disk1/snapraid.contentcontent /media/disk2/snapraid.contentcontent /media/disk3/snapraid.content# 指定数据盘及其挂载点# 这里不一定要写确切的挂载点，可以是这块盘上的任意目录# 目录以外的内容会被完全忽略data d1 /media/disk1/data d2 /media/disk2/# 忽略所有隐藏文件和目录（不做冗余）# 在 Unix-like 里就是 . 开头的文件和目录# 在 Windows 里就是带隐藏属性的文件和目录nohidden# 排除列表与包含列表，注意顺序！下文详解exclude *.unrecoverableexclude *.nobackupexclude *.nobackup/exclude /tmp/exclude /lost+found/#include /foo#include /bar/# 生成校验数据时，每处理 10 GiB 数据自动保存一次，方便断点继续autosave 10 写好配置文件之后，使用 snapraid sync 进行首次同步，也就是根据数据盘的内容生成校验盘的内容。我的第一次同步花了 24 小时： 12345678910111213141516Scanning disk d1...Scanning disk d2...Using 221 MiB of memory for the FileSystem.Initializing...Resizing...Saving state to /home/snapraid/snapraid.content...Saving state to /media/disk1/snapraid.content...Saving state to /media/disk2/snapraid.content...Saving state to /media/disk3/snapraid.content...Verifying /home/snapraid/snapraid.content...Verifying /media/disk1/snapraid.content...Verifying /media/disk2/snapraid.content...Verifying /media/disk3/snapraid.content...Syncing...Using 24 MiB of memory for 32 blocks of IO cache.0%, 959 MB, 40 MB/s, CPU 1%, 24:08 ETA 常用的 SnapRAID 命令： snapraid sync：根据数据盘生成校验盘； snapraid diff：查看有哪些数据需要 sync； snapraid status：查看磁盘阵列的状态； snapraid scrub：进行数据擦洗，提早发现磁盘阵列中的错误。 SnapRAID 首次同步完成之后，可以将 snapraid sync 和 snapraid scrub 加入 cron / systemd timer，定时运行。后者默认配置下每次运行擦洗全部数据的 8%，并且会挑选最近 10 天内没有被擦洗过的数据进行擦洗。如果每天运行一次 snapraid scrub 的话，每 12.5 天所有数据都会被擦洗一遍，形成一个健康的循环。 当擦洗发现有数据损坏，或是更糟糕地，某天整块磁盘挂了（不转了），就需要修复数据了。这时候应该做的是停掉所有的定时任务，然后换上新的磁盘，然后用 snapraid fix -d name_of_disk 命令，根据健在磁盘的内容，在新磁盘里重建坏掉磁盘里的内容。只要坏掉的磁盘数量小于等于校验盘的数量，SnapRAID 都能完整地修复数据。 由于 snapraid sync 是定期执行的，这意味着在下次同步之前，磁盘阵列是有机会恢复到上次同步的状态的，因此 snapraid fix 除了可以重建整个磁盘，也可以重建单个文件，也就是反删除。如果你误删除了文件，可以用 snapraid fix -f path/to/file 来恢复文件到上次同步时的状态。 六、SnapRAID 最佳实践事实上我也就昨天才开始用 SnapRAID，所以这所谓的「最佳实践」，其实也只是我在阅读文档和配置使用中觉得需要注意的地方。 排除列表与包含列表因为 SnapRAID 是工作在文件系统之上、基于目录的冗余存储方案，因此可以很方便选择哪些目录和文件需要做冗余，哪些不需要。在配置文件中 include 和 exclude 的规则如下： 可以使用 * ? [1-3] 这样的简单通配符； 以 / 开头的路径匹配的是数据盘的根目录，而不是系统的根目录； 以 / 结尾的路径只会匹配目录； 不以 / 结尾的路径只会匹配文件； 如果最后一条规则是包含（include），则所有未匹配的路径都会被排除； 如果最后一条规则是排除（exclude），则所有未匹配的路径都会被包含。 适合使用 SnapRAID 的文件因为 SnapRAID 是定期运行的，在两次 snapraid sync 之间新增的数据是有一段时间没有冗余的，这时候如果磁盘挂了，那这些数据就丢失了。因此，SnapRAID 并不适合用来对频繁变动的文件（如：系统盘）做冗余。 SnapRAID 比较适用的场景是体积巨大、但是很少更改的文件。比如对摄影爱好者来说，磁盘中可能会有好几个 TiB 的 RAW 照片或是未剪辑的 4K 视频文件。这些原始文件因为体积巨大，很难通过互联网做异地备份，而它们本身几乎不会再发生变化，因此非常适合用 SnapRAID 做冗余。由于 SnapRAID 的灵活配置，用户可以方便地选择对哪些文件做冗余，也可以随时将单个磁盘从阵列中临时脱离出来，直接插到图形工作站上进行高速读写。 与 mergerfs 配合SnapRAID 提供了类似 RAID 的冗余功能，但是 RAID 还能将磁盘阵列里的磁盘合并成一个大磁盘。SnapRAID 本身并不提供合并磁盘的功能，但是 mergerfs 可以达成这个目的：《使用 mergerfs 合并多块硬盘的剩余空间》。 七、致谢感谢 Jimmy Xu 在本文发表前，对本文奇偶校验算法相关的内容进行技术评测，并提出了宝贵的修改意见。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>nas</tag>
        <tag>raid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用EverAver+Emby+Kodi打造本地AV（毛片）媒体库]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%88%A9%E7%94%A8EverAver-Emby-Kodi%E6%89%93%E9%80%A0%E6%9C%AC%E5%9C%B0AV%EF%BC%88%E6%AF%9B%E7%89%87%EF%BC%89%E5%AA%92%E4%BD%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[让AV再次伟大! W A R N I N G ！ ※阅读正文前请保持房间明亮，并年满18岁。 ——只为给伟大的日本劳动女性献上赞歌。 本文将深入浅出，从无到有，以日本“成人视频”为例。 ——由影片元数据抓取（EverAver）开始，到服务端软件选择（Emby），再到客户端配置（Kodi），做出完整的教程指南。 无论您是搭建本地媒体库，还是影片归类管理，相信都能在文中找到合适工具。 请善用文章右侧的CATALOG快速跳转至您需要的教程。 元数据 / EverAver什么是“元数据”元数据（metadata）即影片信息：如影片封面 / 影片标题 / 发行时间 / 影片简介 / 制作公司 / 演员表 / Staff表。 越是完善的元数据，导入plex/emby等本地媒体库后就越是美观便利。 就像这样： 而我们平时下片 发电 显然不会保留这些信息。 所以搭建本地片库的第一步，便是补全影片元数据。 元数据有四种抓法就像Android App的网络访问方式有四种，元数据抓取也有的是招： Plex / Emby自带“刮削器” 普通电影/日本动画使用自带tmdb/anidb等刮削器（metadata agents）便能实现元数据自动抓取。 成人类视频的刮削器则在plex/emby的社区论坛内提供，作为扩展插件安装即可。 但刮削器对文件名要求极高，视频文件名必须需包含影片英文名（普通视频）或番号（成人视频）。 而我们下载的AV却普遍如下画风 自动工具根本无法应对如此复杂且混乱的命名方式。 要么识别错误，要么无法识别，而一旦识别错误，改起来更是蛋疼无比，因为你甚至不知道哪部错了。 ——日本爱情动作片对不懂爱的“自动程序”而言，显然是超纲了。 JavHelper 一款由台湾人开发的AV元数据抓取工具。 集自动重命名 / 元数据抓取 / 大批量操作于一身。 弊端与plex/emby的刮削器相同，基于程序识别的“自动批量”终有极限，虽识别精度高于刮削器，但依然不是可用级别。 并且该软件抓取的元数据相对简陋，只有单张封面和简单信息，无法满足搭建“媒体库”的需求。 ——仅适用于轻度粗略的文件管理。 EverAver 又一款台湾人开发的AV元数据抓取工具。 功能强大： 自动识别番号并抓取元数据，无法识别的影片能立刻通过手动输入查询，彻底杜绝“识别错误”。 元数据信息非常完善，并提供多个版本供人选择； 支持自动重命名； 支持自动建立文件夹并归类（如按“女优名字”建立分类文件夹），给媒体库的本地管理提供了巨大便利； 几乎所有影片都能正确抓取元数据，本次搭建媒体库合计扫描800+部作品，只有24部没有找到； 没找到元数据的作品，支持手动添加补全信息。 缺点则是： 不支持批量，需要一部一部抓取； 对存在多个分集的作品支持不好，需手动修改nfo文件进行合并（将在后文详述）； 为了速度，推荐挂日本代理使用。 由于EverAver功能强大且没有致命缺陷，自然成为本次媒体库搭建的主力工具。 ——为毛片 / 里番管理而生！ 手动编辑nfo 原始但有效。 以EverAver生成的数据为例，影片元数据通常以nfo文件+封面/封底图片的形式，储存于影片同目录。 用文本文档 / 编辑器打开nfo文件便能看到整个元数据的结构与编写规则。 规则非常简单，看tag英文便能明白需要填入什么，比如： 12345678910111213&lt;movie&gt; &lt;title&gt;影片标题&lt;/title&gt; &lt;studio&gt;制作组&lt;/studio&gt; &lt;year&gt;发行年份&lt;/year&gt; &lt;premiered&gt;具体发行时间&lt;/premiered&gt; &lt;outline&gt;影片大纲&lt;/outline&gt; &lt;plot&gt;内容简介&lt;/plot&gt; &lt;runtime&gt;影片时长&lt;/runtime&gt; &lt;director&gt;导演&lt;/director&gt; &lt;actor&gt; &lt;name&gt;演员&lt;/name&gt; &lt;/actor&gt;&lt;/movie&gt; 更多的nfo编写规则请参阅wiki：NFO files。 优缺点不言自明，纯人工是最准确的方案，也是最费事的方案。 而当我们无法通过软件找到影片元数据时，也只能参考日本通贩网站上的信息（如DMM），手动编写nfo了。 ——软件搞不定问题的话，用人力搞定不就行了？ 明确文件夹层级比起通过plex/emby的媒体库页面管理影片，在windows资源管理器添加网络位置映射NAS上的硬盘，通过smb管理文件显然更加便利。 所以我们在动工之前，最好明确影片存放层级，利用文件夹归类。 我的目录层级如下： 1234硬盘根目录/顶层文件夹——演员实用度/等级（第一层子文件夹）————演员名字（第二层子文件夹）–——————演员所有影片 为了方便理解，我特地把原本N/R/SR/SSR/UR的沙雕抽卡等级改成了“星级”。 毕竟出演AV的老师实在太多，不划分层级并归类，直接全扔一起会完全不知道谁是谁。 当然—— ——您也能按个人性癖归类（比如裤袜 / 屁股 / 熟女 / JK）。 这里我只提供一种归类思路，而明确想要的文件夹层级后，才能配置EverAver做到搭配使用。 换做普通电影 / 日本动画，做一层“星级目录”也能当作一种豆瓣式的“评分”筛选，最后在Emby的媒体库能更方便的找到喜爱作品。 不得不说Emby的“评分系统”只有“喜欢/不喜欢”，实在残废。 配置EverAverEverAver的默认规则会建立复杂的文件名+繁琐的文件夹层级，使用前请按需修改配置。 点击右上角设定： 第一页操作设定勾选如下： 第二页搜寻设定勾选如下： 需要填写的部分保持默认，排除特定文字的规则可按需增加（用来过滤文件名中的垃圾信息以识别番号）。 第三页命名设定勾选如下： 格式设定中的命名格式修改为： 1234%actor% - [%year%] %title% [%num%]显示效果如下：女优名字 - [作品年份] 作品标题 [作品番号].mp4 建立层级目录修改为： 1#%actor% 务必加一个符号在%actor%前面（如“#”号），否则导入时Emby会将演员目录下的所有片子错误识别成“同一作品”。 更名设定的第一项建议修改为： 1NULL EverAver配置完毕。 使用EverAver使用前请在搜寻品番的文本框内右键，选择你的影片类型。 将一部AV拖入软件，EverAver会自动提取出番号，并填写在搜寻品番的文本框内。 偶尔番号会提取不干净 / 错误，请手动修改，不用在意大小写。 点开始搜寻便开始抓取元数据。 抓取到多个版本的元数据时，点击封面右下角进行切换，选择最完善的一个； 第一个版本的元数据封面尺寸偶尔会偏扁，请切换元数据版本解决； （偏扁的封面会被Emby拉伸，非常难看） 品番一栏便是番号，有时会出现R/TK之类的无用前缀，推荐删除； 片名一栏也不时出现【数量限定】的无用前缀，为保持Emby的媒体库排序整洁，务必删除。 元数据确认无误后，点右下角重新命名便会按我们配置的规则，自动生成目录+移动文件+添加封面与nfo文件+重命名。 一部AV影片的元数据便抓取完成。 修改nfo合并“多集作品”上文提到，EverAver不支持具有多个分集的“大型”作品，比如这部。 解决方法很简单： 用EverAver抓取并重新命名其中一集，获得封面与nfo文件。 用编辑器打开并编辑nfo文件。 在&lt;title&gt; &lt;poster&gt; &lt;thumb&gt; &lt;fanart&gt;四个tag的文件名末尾，添加数字代表集数，我用的是CD1 / CD2 / CD3。 重命名硬盘里的图片 / 视频 / nfo文件，让它们与&lt;poster&gt; &lt;thumb&gt; &lt;fanart&gt;指定的文件名保持一致。 重复上述操作，直到每集都修改完毕，最后以影片名字新建一层文件夹，将影片全部拖入即可： 在Emby中，其它集数将作为“附加内容”展示。 元数据部分的教程至此结束。 现在让我们泡壶红茶，放段评书，重复以上操作，直到片库整理完毕。 最终完成效果如图（右键查看大图）： 服务端 / EmbyEmby与Plex市面上成熟的本地媒体库工具，无外乎Emby与Plex。 在搭建AV / 里番的媒体库上： Plex根本无法正确读取我们手动抓取创建的nfo文件与封面，直接出局。 在搭建普通电影 / 动画的媒体库上： Emby的刮削器（metadata agents）更加强大，并且集成官方插件库，非常方便。 在移动客户端上： Plex除网页与桌面客户端外的所有移动客户端均需要购入会员解锁使用。 Emby类似，但Android客户端能免费使用。 在TV客户端 / Kodi插件上： 两者的官方TV客户端都是废品，Plex不支持本地硬解（现在似乎支持了），Emby则无法识别有线网络连接，并且都收费。 作为TV客户端的免费替代，Plex的Kodi插件非常简陋。 Emby则官方提供emby与embycon两套插件，前者能拉取媒体库，后者能浏览媒体库的本地目录，并提供一套风骚的Kodi皮肤。 在服务迁移上： Emby有一个开源分支替代，Plex则相对封闭。 此前因不满Emby的闭源决定，由用户社区独立出的Jellyfin在功能乃至界面上与Emby无异，并且自由免费。 如果未来Emby官方出现作死问题，在数据上可以完全无痛的迁移到Jellyfin。 （※Jellyfin的客户端目前问题不少，不推荐需要稳定体验的普通用户使用。） 安装Emby并添加媒体库打开Emby官网，按照您的NAS系统下载安装对应的Emby服务端软件： 安装完成会弹出设置引导，选择您的语言，然后下一步。 添加媒体库推荐跳过，直接下一步。 首选元数据（metadata）的语言/国家，选择“日本”并下一步。 剩下几页保持默认，一直下一步直到完成引导。 如果您在引导开头将语言设置为简体中文，请重启Emby服务端软件以生效。 在浏览器输入网址 您的Emby服务端本地IP:8096 进入Emby主页面； 点击左上角“汉堡菜单”→管理服务器进入控制台。 左侧每个项目都可以进去看看，按需开启/关闭功能，比如开机启动 / 转码方式 / 定制通知之类，不做赘述。 我个人关闭了DLNA，并删除了完全用不上的自带刮削器插件，只保留了两个。 最后选择媒体库→添加媒体库。 内容类型内选择电影，勾选右上显示高级设置，点击“+号”添加我们此前整理的AV文件夹。 媒体库设置则按图勾选（实时监控自行选择是否开启）： 其它保持默认，确定后回到控制台，点击扫描所有媒体库。 自定义Emby皮肤Emby原生支持自定义css，官方论坛中有很多样式。 我选择了一个简单的暗色主题，只需进入网站 点击你喜欢的颜色，css代码便复制到了剪贴板。 回到Emby控制台，进入设置，将代码粘贴至自定义css，保存并刷新网页即可。 多用户管理+骚操作Emby有非常强大的“多用户管理”功能。 可以额外添加多个“用户”，并指定用户的媒体库编辑/访问权限，做到每个账户都能拥有“专属”的媒体库，如： “电影”给老爸； “韩剧”给老妈； “卡通”给小鬼； “毛片”给弟兄。 这里我们重点注意删除权限的管理。 ——任何账户都最好关闭删除媒体的权限，以防悲剧。 （emby的“删除视频”是彻底删除，没有挽回余地） 而当你的弟兄们正通过Emby客户端访问媒体库，并开始看片儿时。 你不仅能通过网页控制台暂停 / 播放 / 停止客户端正在播放的视频，还能直接拖动的它的进度条。 你甚至能向客户端发送消息文本： 将在客户端左下角弹窗显示： 可以用来恶作剧，比如发一整段的《般若心经》在对方性致昂然时盖住对方屏幕。 ※本操作引发的一切后果请自行承担。 一切努力都是值得的由于我们已经用EverAver抓完元数据并做好分类，Emby导入媒体库的过程其实飞快。 当媒体库扫描完成后，让我们重返Emby首页。 ——本地AV媒体库已经完全成型： 点击我的媒体下的电影即可进入完整列表，浏览 / 筛选 / 搜索影片： 点进一部影片，我们抓取的所有元数据都正常显示，Emby还会向您贴心推荐“更多类似”： 由于都是些“俩人就能演完的小电影儿”。 Emby这套为普通电影 / 动画 / 电视剧设计的布局，在只有一个“女演员”时会显得很空。 让我们点击老师名字，她的参演作品也将完整呈现： 进入文件夹，此前我们按“星级”归类的文件夹，同样可以通过Emby网页/客户端直接浏览。 这时的浏览逻辑已经与windows资源管理器无异，点进一个文件夹就能看见我们之前按#演员名字命名的目录。 还有作品封面作为文件夹预览，从此不怕忘记老师是谁！ 是啊，我们一直以来累积的东西并没有白费。 今后也是，只要我们不停下脚步，道路就会不断延伸—— 所以，所以啊！ ——不要停下来啊！（指丰富本地毛片库） 服务端部分的教程至此结束。 客户端 / Kodi上文服务端部分已经在开头提到，Emby/Plex的TV端不仅废品还收费。 所以推荐使用Kodi+插件作为TV端，来做到0成本的本地解码播放。 ※鉴于Kodi的操作逻辑异常反人类，本部分将以详细图文的形式写教程。 设置Kodi为中文打开Kodi，进入系统设置。 进入Interface。 将Fonts修改为Arial based。 （无论语言为何都必须修改字体，默认字体将无法显示AV媒体库中的日文。） 进入Regional，修改语言为中文。 添加Emby官方源并安装插件库回到系统设置，进入文件管理。 点击添加源。 输入路径http://kodi.emby.media，命名为emby后确定。 回到系统设置，进入系统。 选择插件，将未知来源打开。 回到系统设置，进入插件。 点击从zip文件安装。 进入我们刚刚添加的emby。 点击repository.emby.kodi-1.0.4.zip以安装插件库。 安装Emby视频插件插件库安装完毕后，点击从库安装。 按目录进入Kodi Emby Addons→视频插件→Emby。 点击安装。 安装完毕会弹出配置对话框。 一般会自动扫描到服务端，比如我的NAS。 如果没有，则点击Manually add server手动输入您的服务端ip与端口。 连接服务端后点击用户头像登录。 随后会弹出一系列对话框，如： 选择图片缓存方式； 是否同步empty（没用选“否”）； 是否同步烂番茄评分（更没用同样选“否”）之类。 请按需选择。 最后会让您选择需要同步到Kodi的媒体库，点击Proceed继续。 选择您想同步的媒体库名称（如我的AV媒体库就叫“电影”）后确定便开始同步。 同步会很快完成。 返回Kodi主页，能看到Emby里的“小电影”已经全部出现在Kodi中。 如果没有进阶需求，此时就可以完成Kodi配置并投入使用了。 调整Kodi快进速度Kodi默认快进/快退速度非常反人类，推荐调整。 打开系统设置，进入播放器。 将跳过步骤改为如下设置即可。 换上Embuary皮肤Kodi的默认皮肤长得过于“避孕”，好在emby官方提供了一套风骚的Kodi皮肤——Embuary。 打开系统设置，进入插件。 按目录进入从库安装→Kodi Emby Addons→界面外观→皮肤。 选择对应Kodi版本的皮肤并安装。 安装完毕不要立即切换，会乱码。 打开系统设置，进入界面。 切换皮肤到Embuary。 然后顶着乱码点左侧的“按钮”，以确认切换皮肤。 再顶着乱码把字体改为Arial，随后字体显示恢复正常。 回到Kodi首页会弹出提示，选择OK，do it for me。 Emby皮肤安装完毕。 从此，Kodi无论主页还是播放控件都成了Emby的形状： 此前提到的“多集作品”，同样可以正常播放。 点击播放控件的“列表按钮”便能选择集数。 除此之外，这套皮肤还有丰富的界面自定义功能。 打开系统设置，进入皮肤设置就能自定义首页控件。 这部分写起来过于繁琐，推荐修改的项目已用红框框出，请自行研究。 我个人将标题 / 年份 / 演员 / 制作公司几个项目添加到主页menu方便快速筛选，并移除了游戏 / 插件 / android应用等无用项目。 widget同样移除一堆无用项目，修改皮肤配色后的最终成品如图： 选装EmbyCon视频插件EmbyCon的用处只有一个，就是配合Embuary皮肤使用时，能快速访问我们此前在NAS上按“星级”归类的本地文件夹。 无此需求不用安装。 打开系统设置，进入插件。 按目录进入从库安装→Kodi Emby Addons→视频插件→EmbyCon。 选择版本号高的安装。 按提示填入你的Emby服务端ip与端口，选择账户并登录。 如果你已经装好Embuary皮肤，此时会发现首页多了个“入口”控件。 进入后就能看见本地文件夹了。 连接Kore遥控器(#%E8%BF%9E%E6%8E%A5kore%E9%81%A5%E6%8E%A7%E5%99%A8)由于Kodi“太重”，各项操作都不跟手，于是决定用手机遥控器提升体验。 遥控器用的Kore，干净免费功能强大。 配置虽然有官方教程，但已经过时，所以这里将重新总结： 打开系统设置，进入服务。 开启红框内的项目即可。 （端口为避免冲突，改为8083之类就好。） 掏出手机，打开Kore，马上就能扫描到你的Kodi，点击添加。 没有就按照提示，手动输入电视盒子ip与刚刚修改的Kodi端口添加。 添加成功后能通过手机浏览媒体库，控制视频播放，快速关闭Kodi，etc. 最实用的莫过于可以在手机上“拖拽”控制Kodi进度条。 别忘了设置Kodi密码！(#%E5%88%AB%E5%BF%98%E4%BA%86%E8%AE%BE%E7%BD%AEkodi%E5%AF%86%E7%A0%81)——无数前人用血的教训告诉我们：做事要锁门。 打开系统设置，进入用户配置，开启启动时显示登录界面。 进入左侧的另一个用户配置，点击Master user。 进入锁定偏好设置，在管理员锁定一栏添加密码并确定。 其它项目保持默认即可。 重启Kodi，此时就会要求密码登录了。 客户端部分的教程至此结束。 全部教程也至此完结。 若您能从本篇指南中获得一点参考，将是我最大的荣幸。 尾巴做完片库，写完文章，我坐在电视机前，优雅的褪去裤子。 左手端着红茶，右手握着法杖—— ——屏幕中1920*1080的日本工作女性正以29.96 fps的稳定帧率朝我微笑。 ——她婀娜着身姿，透过喇叭传出48kHz 16bit的撩人娇声。 曾几何时，拥有自搭AV片库是我的一大梦想。 当梦想实现之时，一切竟索然无味。 本次片库的完整搭建耗时不过一周，搭建完成后却没再使用，以至于拖到月底才整理成文。 一点一点搭建出片库的折腾过程，其乐趣早已凌驾于影片本身。 关闭电视，掏出手机。 点开由田辺京老师绘制的儿童色情漫画—— ——“还是纸片人适合老子。”]]></content>
      <categories>
        <category>停车场</category>
      </categories>
      <tags>
        <tag>adult</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H.264视频编码推荐的分辨率和码率配置表]]></title>
    <url>%2F2019%2F09%2F28%2FH-264%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E6%8E%A8%E8%8D%90%E7%9A%84%E5%88%86%E8%BE%A8%E7%8E%87%E5%92%8C%E7%A0%81%E7%8E%87%E9%85%8D%E7%BD%AE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[在各种视频编码标准中，行业一直在求追“高压缩比（数据量越小越好）”，同时又保证“高视频质量”的算法。鱼和熊掌不可兼得，视频编码是一种折中的游戏。参数“视频码率”的设定，就代表了这种折中的选择。码率越高，数据量越大，视频质量越好，码率越小，数据量越小，视频质量越差。 但是，码率大到一定阈值之后，码率的提升带来的视频质量改善就会变得微不足道，所以这个码率阈值就显得非常重要。 网上这篇文章「Video Encoding Settings for H.264 Excellence」，就针对H.264视频编码，测试了不同视频分辨率下的码率阈值。 其介绍了用于高质量H.264视频编码的一组分辨率，码率设置，以及这些选择背后的推理。这篇文章很好的帮我们解答了：针对H.264视频编码（对其他视频编码格式无效），给定一个视频分辨率，要设置什么视频码率，才能得到“最具性价比”的高质量视频画面。 针对H.264编码格式，根据不同分辨率，推荐其对应的码率配置关系如下图所示： 宽屏 非宽屏]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[df-dferh-01 中国区 Android 安装 Google Play Store 后报错 的 解决办法]]></title>
    <url>%2F2019%2F09%2F28%2Fdf-dferh-01-%E4%B8%AD%E5%9B%BD%E5%8C%BA-Android-%E5%AE%89%E8%A3%85-Google-Play-Store-%E5%90%8E%E6%8A%A5%E9%94%99-%E7%9A%84-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[访问goole play显示从服务器检索信息时出错。[DF-DFERH-01] 问题从服务器检索信息时出错。[DF-DFERH-01] 这时候我们就需要自己安装它，安装的办法有很多，这里不再赘述。总之，一但你安装好，就会发现，即使开了代理，Play Store 也有可能在登录后无法正常加载内容（登录是正常的）。 此时会显示错误：df-dferh-01 遇到这个错误，那么多半你的设备是内置了谷歌服务的，且你的代理工具是根据规则进行分流，如果你使用全局的 vpn，那么应该不会遇到这个错误。 遇到这个错误的原因是内置的谷歌服务，是厂商经过定制的，他们会把谷歌的域名设定为 cn 域名，即 googleapis.cn，很遗憾，这个域名会被解析到中国某公司，显然，你的 Play Store 得不到任何数据——于是就报错了。 解决办法修改你的代理工具规则，加入一条，让 googleapis.cn 走代理即可。当然，你也可以修改路由器的 dns，把 googleapis.cn 强行解析到 googleapis.com。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ffmpeg转码、截取、合并、调速、提取]]></title>
    <url>%2F2019%2F09%2F28%2Fffmpeg%E8%BD%AC%E7%A0%81%E3%80%81%E6%8F%90%E5%8F%96%E3%80%81%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[ffmpeg一些常用功能 转码、截取、合并、调速、提取 转码12345ffmpeg -i out.ogv -vcodec h264 out.mp4ffmpeg -i out.ogv -vcodec mpeg4 out.mp4ffmpeg -i out.ogv -vcodec libxvid out.mp4ffmpeg -i out.mp4 -vcodec wmv1 out.wmvffmpeg -i out.mp4 -vcodec wmv2 out.wmv -i 后面是输入文件名。-vcodec 后面是编码格式，h264 最佳，但 Windows 系统默认不安装。如果是要插入 ppt 的视频，选择 wmv1 或 wmv2 基本上万无一失。 附加选项：-r 指定帧率，-s 指定分辨率，-b 指定比特率；于此同时可以对声道进行转码，-acodec 指定音频编码，-ab 指定音频比特率，-ac 指定声道数，例如 1ffmpeg -i out.ogv -s 640x480 -b 500k -vcodec h264 -r 29.97 -acodec libfaac -ab 48k -ac 2 out.mp4 截取用 -ss 和 -t 选项， 从第 30 秒开始，向后截取 10 秒的视频，并保存： 12ffmpeg -i input.wmv -ss 00:00:30.0 -c copy -t 00:00:10.0 output.wmvffmpeg -i input.wmv -ss 30 -c copy -t 10 output.wmv 达成相同效果，也可以用 -ss 和 -to 选项， 从第 30 秒截取到第 40 秒: 1ffmpeg -i input.wmv -ss 30 -c copy -to 40 output.wmv 值得注意的是，ffmpeg 为了加速，会使用关键帧技术， 所以有时剪切出来的结果在起止时间上未必准确。 通常来说，把 -ss 选项放在 -i 之前，会使用关键帧技术； 把 -ss 选项放在 -i 之后，则不使用关键帧技术。 如果要使用关键帧技术又要保留时间戳，可以加上 -copyts 选项： 1ffmpeg -ss 00:01:00 -i video.mp4 -to 00:02:00 -c copy -copyts cut.mp4 合并把两个视频文件合并成一个。 方法一简单地使用 concat demuxer，示例： 123456$ cat mylist.txtfile '/path/to/file1'file '/path/to/file2'file '/path/to/file3'$ ffmpeg -f concat -i mylist.txt -c copy output 更多时候，由于输入文件的多样性，需要转成中间格式再合成： 方法二1234ffmpeg -i input1.avi -qscale:v 1 intermediate1.mpgffmpeg -i input2.avi -qscale:v 1 intermediate2.mpgcat intermediate1.mpg intermediate2.mpg &gt; intermediate_all.mpgffmpeg -i intermediate_all.mpg -qscale:v 2 output.avi 调速加速四倍：1ffmpeg -i TheOrigin.mp4 -vf "setpts=0.25*PTS" UpTheOrigin.mp4 四倍慢速：1ffmpeg -i TheOrigin.mp4 -vf "setpts=4*PTS" DownTheOrigin.mp4 提取增加字幕1ffmpeg -i video.avi -i sub.ass -map 0:0 -map 0:1 -map 1 -c:a copy -c:v copy -c:s copy video.mkv 提取字幕1ffmpeg -i input.mp4 -map 0:3 output.srt 提取视频1ffmpeg -i Life.of.Pi.has.subtitles.mkv -vcodec copy –an videoNoAudioSubtitle.mp4 提取音频1ffmpeg -i Life.of.Pi.has.subtitles.mkv -vn -acodec copy audio.ac3 修改默认的音频轨道1ffmpeg -i input.mkv -map 0:0 -map 0:1 -map 0:2 -c copy -disposition:a:0 default -y output.mp4 输入文件包含一个视频轨道，两个音频轨道 0:0 表示视频轨道0:1 表示第一个音频轨道0:2 表示第二个音频轨道 -c copy 复制编码，也即是编码不变 最关键的，-disposition:a:0 default设置音频轨道的第一个为默认值 清空元数据1ffmpeg -i input.mp4 -map 0:0 -map 0:1 -map 0:2 -map_metadata -1 -c:v copy -c:a copy output.mp4]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[exiftools常用命令]]></title>
    <url>%2F2019%2F09%2F28%2Fexiftools%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[exiftools常用命令记录 批量修改文件名123exiftool -d %Y-%m-%d_%H-%M-%S%%-c.%%e "-filename&lt;MediaCreateDate" .\1.mp4exiftool -d %Y-%m-%d_%H-%M-%S%%-c.%%e "-filename&lt;DateTimeOriginal" .\exiftool -d %Y-%m-%d_%H-%M-%S%%-c.%%e "-filename&lt;FileModifyDate" .\ 通过修改时间写入拍摄日期12exiftool "-DateTimeOriginal&lt;FileModifyDate" -r -overwrite_original .\exiftool "-FileModifyDate&lt;DateTimeOriginal" -r -overwrite_original .\ 写入指定时间12exiftool "-DateTimeOriginal='2008-05-01_08:00:00'" -r -overwrite_original .\exiftool "-FileModifyDate='2008-05-01_08:00:00'" -r -overwrite_original .\ 写入视频媒体创作时间1exiftool "-FileModifyDate&lt;filename" "-CreateDate&lt;filename" "-MediaModifyDate&lt;filename" "-MediaCreateDate&lt;filename" -api quicktimeutc=1 -quicktime:createdate&lt;filename -overwrite_original *.mp4]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[屌丝UPS通过ping实现NAS断电自动关机]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%B1%8C%E4%B8%9DUPS%E9%80%9A%E8%BF%87ping%E5%AE%9E%E7%8E%B0NAS%E6%96%AD%E7%94%B5%E8%87%AA%E5%8A%A8%E5%85%B3%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[何谓屌丝UPS，就是普通的不能再普通UPS，没有高级货的USB或者网络接口，只有电源接口，唯一的好处就是价格便宜，断电的时候可以维持NAS供电一段时间，但是由于没有通信功能，在Q家或者其他的NAS UPS配置中无法启用断电自动关机，所以如果不想个办法，是无法断电关机的，突然断电对于NAS的危害我就不说了，还有如果你已经有APC BK650等高帅富级UPS，您也可以略过这篇文章了。 以下参考了网上的一些资料和自己的一些摸索，如有雷同，纯属巧合，本人不负责任的： 说一下思路，其实是ups只接NAS，路由接市电，通过每隔一定时间通过NAS ping路由IP地址来确认是否停电，如果ping没有问题，就是有电，如果突然断电，ping不通了，就认为断电，执行关机命令。 首先winscp或者putty进NAS，在/usr/sbin/下建立TG500.sh文件，内容如下： 123456789101112#!/bin/shping -c 1 192.168.1.1 &gt; /dev/nullret=$?if [ $ret -eq 0 ]thenecho ' AC Power OK ! 'elseecho ' AC Power maybe off, checking again after 4 minutes ! 'sleep 240/usr/sbin/TG500-2.shfi winscp修改属性为0755,赋予可执行权限，以上内容可能各位lunix达人一看便知，是一个检测脚本，如果ping的通路由的ip，就说明市电正常，不通的话再次检测确认，为什么要再次检测，因为有可能你的路由重启，或者是其它什么情况导致暂时ping不通，所以要再次检测确认，我这里是隔了4分钟，一般4分钟足够路由重启了。 还有这个TG500.sh文件为什么要放在/usr/sbin/目录，因为我试过如果放在NAS本身的一些目录中，如/etc或者/sbin等系统自带目录，重启后自检会删除你新增的文件，导致脚本失效，所以只能放在/usr/下面的子目录中。 继续在/usr/sbin/下建立TG500-2.sh文件，内容如下： 1234567891011#!/bin/shping -c 1 192.168.1.1 &gt; /dev/nullret=$?if [ $ret -eq 0 ]thenecho ' AC Power OK ! 'elseecho ' AC Power off, shut down NAS ! '/sbin/powerofffi 同样winscp修改属性为0755,赋予可执行权限，这个就是再次确认脚本，如果过了4分钟再次ping路由还是不通，就关机。 然后修改/etc/config/crontab文件，增加一条 1*/5 * * * * /usr/sbin/TG500.sh 就是每5分钟执行一次检测脚本，保存后关机重启NAS即可，通过以上的脚本，得到的效果是如果断电，那么在9-14分钟内NAS就会自动关闭，如果路由只是重启，4分钟内不会关闭NAS（再次确认一下。NAS接UPS,路由接市电，路由的ip地址为192.168.1.1），从而保护了我们的硬盘和数据，将突然断电的风险降到最低,本人亲测有效（在Q家419PII上测试通过，理论上支持其他Q家的NAS，但是不保证，为此测试脚本重启NAS接近10次，走了不少弯路，郁闷呀-_-） 以上可以根据你自己的路由ip地址和UPS能力来修改检测时间。其实还可以在路由写个类似脚本，来实现来电自动开机，但是无奈屌丝级伪QS419PII的网络唤醒有问题，就没法实现了，只能遗憾了，不过来电自动开机感觉没有断电自动关机重要，有以上作为一个标准屌丝的我已经很满足了。]]></content>
      <categories>
        <category>nas</category>
      </categories>
      <tags>
        <tag>nas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome 清除某个特定网站下的缓存]]></title>
    <url>%2F2019%2F09%2F28%2FChrome-%E6%B8%85%E9%99%A4%E6%9F%90%E4%B8%AA%E7%89%B9%E5%AE%9A%E7%BD%91%E7%AB%99%E4%B8%8B%E7%9A%84%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[有时候我们需要单独清空某个网站的缓存，但是chrome并没有提供单独删除某个站缓存的功能，这里有个小技巧 打开开发者工具（F12），选择 Network——Disable cache 即可。需要清除某网站缓存时 F12 打开开发者工具就会自动清除这个网站的缓存，而不必清除所有网站的缓存了。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>software</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新安装windows无法选择版本的问题]]></title>
    <url>%2F2019%2F09%2F28%2F%E9%87%8D%E6%96%B0%E5%AE%89%E8%A3%85windows%E6%97%A0%E6%B3%95%E9%80%89%E6%8B%A9%E7%89%88%E6%9C%AC%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有些品牌机在重新安装系统时无法选择windows版本，默认安装家庭版，解决这个问题很简单 新建txt文档，复制粘贴下面几行字符，保存，修改文件名为ei.cfg(连同后缀名一块修改)。然后将这个文件添加到镜像中的sources文件夹内即可。如果想保存为ISO镜像，需要使用ISO编辑软件添加此文件。如果是通过U盘，硬盘安装，在制作好U盘启动盘或者解压后添加即可。 12345[EditionID][Channel]Retail[VL]0]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式速查表]]></title>
    <url>%2F2019%2F09%2F28%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%9F%E6%9F%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[正则表达式速查表]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用windows自带的资源监视器查看文件占用]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%88%A9%E7%94%A8windows%E8%87%AA%E5%B8%A6%E7%9A%84%E8%B5%84%E6%BA%90%E7%9B%91%E8%A7%86%E5%99%A8%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%8D%A0%E7%94%A8%2F</url>
    <content type="text"><![CDATA[经常当我们删除文件时，有时会提示【操作无法完成，因为文件已在另一个程序中打开，请关闭该文件并重试】，到底是哪些程序呢？ 有时候一个一个找真不是办法，已经被这个问题折磨很久了，今天下决心要把它解决，找到办法了。如果系统是win7以上，可以这么做： 在开始菜单中的搜索框内输入“资源监视器”，回车，打开“资源监视器”。 看下图，在“资源监视器”界面中，点击第二个选项卡“CPU”。在“关联的句柄”右侧搜索框内输入文件名称，点击右侧下拉箭头，就可以查看该文件被那几个程序占用了。 选中程序，右击选择结束进程。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 18.4 HDMI声音有杂音的修复方法]]></title>
    <url>%2F2019%2F09%2F27%2Fubuntu-18-4-HDMI%E5%A3%B0%E9%9F%B3%E6%9C%89%E6%9D%82%E9%9F%B3%E7%9A%84%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[我显示器自带音箱，通过hdmi连接电脑，安装完ubuntu 18后声音出现比较大的杂音… google找到以下方法，亲测完美解决 1sudo pico /etc/pulse/default.pa 在弹出的文本内查找以下字眼 1load-module module-udev-detect 在后面添加tsched=0 完成后像这样 1load-module module-udev-detect tsched=0 重启后世界清静了～～]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Setting up a NUC8i7HVK with Ubuntu 18.04 with AMD VEGAM graphics]]></title>
    <url>%2F2019%2F09%2F27%2FSetting-up-a-NUC8i7HVK-with-Ubuntu-18-04-with-AMD-VEGAM-graphics%2F</url>
    <content type="text"><![CDATA[intel 冥王峡谷安装ubuntu 18 amd显卡的驱动方法 Setting up a NUC8i7HVK with Ubuntu 18.04 with AMD VEGAM graphics I love my NUCs, and when I gave my mine to my daughters to watch movies and play games on, I had a perfect excuse to purchase a shiny new Hades Canyon NUC (NUC8i7HVK) with an AMD Vega M graphics card. Little did I know GNU/Linux wasn’t supported on it; I wrongly assumed that all NUCs were compatible with my preferred OS. I’m not gonna use Windows, so I was forced to put some time into setting up my NUC. Thank goodness for the really smart people who actually figured out how to do it; I’m just documenting the steps I took trom their advice so that others can do the same (I’ve also linked to pretty much every page where I found good advice on this problem). The keystone advice came from user834610 on this page and from a bunch of people here. Note: My Hades Canyon NUC is the one with the i78809G CPU (the more powerful of the two available options). From what I’ve read, at least one of the steps below may fail on the HC NUC with the other CPU. Fair warning!* Update firmware Download the BIOS file from here (use the one for the F7 BIOS Update method) Update the BIOS using these instructions. Install Ubuntu 18.04 from a USB stickMake an Ubuntu startup media on a USB flash drive. I was about to link to the instructions for doing that, but if you don’t know how to do this already, it is probably not a good idea for you to continue down this road; it gets a little hairy if you’re a newbie to GNU/Linux! This NUC is not the place for your first Ubuntu rodeo. Plug in the USB startup media and fire up the NUC. It won’t work. It’ll show you the traditional choices (try Ubuntu, install Ubuntu), but no matter what you choose, you’ll get a black screen. That’s because the Linux grahics card drivers on the live media can’t deal with the hardware. You need to dumb everything down by telling the kernel “nomodeset,” meaning it’s not allowed to start video drivers until the system is running. After turning on the NUC, the moment you see the Grub screen (the try vs install options), press ‘e’. That’ll get you to a screen where you can configure the boot options. Replace the words ‘quiet splash’ with ‘nomodeset’. A bit like this but actually removing the ‘quiet splash’ (because instead of a pretty splash screen now you’ll see what’s actually going on - that’s the not ‘quiet’ part). Press Control-X to exit and boot. Now it should work. Go through the usual process of installing Ubuntu. When it finishes, it’ll fail to boot again, since the newly installed Ubuntu doesn’t have the nomodeset parameter and will try to activate the ungovernable video hardware. Do the whole nomodeset dance again. Here is a pretty good explanation of how to make the nomodeset option persistent (edit the /etc/default/grub file to add the nomodeset and then run sudo update-grub2). I actually just booted, hit Control-Alt-F3 to get to a tty terminal instead of going to the GUI environment, edited the /etc/default/grub file (changed the line GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash&quot; to GRUB_CMDLINE_LINUX_DEFAULT=&quot;nomodeset&quot;, then ran sudo update-grub2 and rebooted. That worked and maybe saved a minute or two. You should end up with a working installation, but you’ll notice that you can’t change the display parameters, the HDMI sound output may not work, and if you try GLmark2, GLXGears -info, or glxinfo, you’ll see that there’s no hardware accleration. In other words, you’ve just put all of your hopes and dreams into the NUC’s graphics card in vain. You are where the person who asked this question was! Now comes the tricky part. In order to get the graphics drivers working, we need to: Upgrade the Linux kernel to 4.18 or higher Grab the vegam firmware blobs needed to talk to the hardware Update Mesa to at least 18.1 Update the kernelUbuntu comes with a frozen kernel. Version 18.04 Bionic Beaver comes with Linux kernel 4.15, and that’s what you get. The drivers for the AMD GPU come with Linux 4.17, and from what I understand serious support comes only with 4.18. In any case, you’ll have to upgrade. You can do that manually like this: 12345wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.18-rc5/linux-headers-4.18.0-041800rc5_4.18.0-041800rc5.201807152130_all.debwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.18-rc5/linux-headers-4.18.0-041800rc5-generic_4.18.0-041800rc5.201807152130_amd64.debwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.18-rc5/linux-image-unsigned-4.18.0-041800rc5-generic_4.18.0-041800rc5.201807152130_amd64.debwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.18-rc5/linux-modules-4.18.0-041800rc5-generic_4.18.0-041800rc5.201807152130_amd64.debsudo dpkg -i linux-*.deb But I cheated and just used UKUU. 123sudo add-apt-repository ppa:teejee2008/ppasudo apt updatesudo apt install ukuu Ran UKUU from the GUI, chose the Linux Kernel 4.18.3, rebooted. Of course, it failed to boot. Because I had to go into the BIOS setup of the NUC and disable Secure Boot. On startup, press F2 to enter the settings, and set Advanced -&gt; Boot -&gt; Secure Boot -&gt; Secure Boot Config -&gt; Secure Boot = unchecked like this After disabling Secure Boot, Ubuntu came up just fine, and running uname -a showed that I was now running the 4.18 kernel. Upgrade Mesa12sudo add-apt-repository ppa:ubuntu-x-swat/updatessudo apt dist-upgrade Grab the AMD Vega M Linux driver and put it in the appropriate directory12wget -m -np https://people.freedesktop.org/~agd5f/radeon_ucode/vegam/sudo cp people.freedesktop.org/~agd5f/radeon_ucode/vegam/*.bin /lib/firmware/amdgpu Then update your Initial Ramdisk to recognize/choose the right kernel: 1sudo /usr/sbin/update-initramfs -u -k all Turn off the nomodeset option again Change the relevant line in /etc/default/grub to GRUB_CMDLINE_LINUX_DEFAULT=&quot;&quot; Run sudo update-grub2 and reboot]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>liunx</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu18.04 修改DNS]]></title>
    <url>%2F2019%2F09%2F26%2FUbuntu18-04-%E4%BF%AE%E6%94%B9DNS%2F</url>
    <content type="text"><![CDATA[最近使用了最新版的ubuntu 18.04运行一些服务，发现服务器经常出现无法解析域名的情况。 检查/etc/resolv.conf文件，发现里面nameserver是127.0.0.53，修改以后过了段时间，又被修改回去，查找资料原来18.04版本DNS是由systemd-resolved管理的。 1netstat -tnpl| grep systemd-resolved 通过以上命令查看到这个服务是监听在53号端口上。 /etc/systemd/resolved.conf大致内容如下： 123456789[Resolve]DNS=223.5.5.5 8.8.8.8#FallbackDNS=#Domains=LLMNR=no#MulticastDNS=no#DNSSEC=no#Cache=yes#DNSStubListener=yes 修改这里面的内容，然后重启systemd-resolved服务即可。 1systemctl restart systemd-resolved.service 如果想要用/etc/resolve.conf控制，直接将systemd-resolved服务停止并禁用。 12systemctl stop systemd-resolved.servicesystemctl disable systemd-resolved.service 这样世界就清净了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>linux</tag>
        <tag>vps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AV女优明星脸]]></title>
    <url>%2F2019%2F09%2F26%2FAV%E5%A5%B3%E4%BC%98%E6%98%8E%E6%98%9F%E8%84%B8%2F</url>
    <content type="text"><![CDATA[撞脸了，看看谁比较靓啦 苍井空 vs 沈傲君 vs 胡杏儿 多野结衣 vs 林志玲 樱井莉亚 vs 张韶涵 秋元美由 vs 田馥甄 朝仓琴美 vs 金莎 麻美由真 vs 贾静雯 秋菜里子(広澤草) vs 苏慧伦 穗花 vs 陈绮贞 相澤莉娜(月本みほの) vs 梁文音 白石茉莉奈 vs 茵芙 大桥未久 vs 蔡卓妍 上原结衣 vs 新垣结衣 樱木凛 vs 卓文萱 今村美穗 vs 郭书瑶 高井桃 vs 戈伟如 妃悠爱 vs 朱琦郁 一之濑亚美莉 vs 陈乔恩 石原莉奈 vs 梁静茹]]></content>
      <categories>
        <category>停车场</category>
      </categories>
      <tags>
        <tag>adult</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My favorite Western Porn Stars]]></title>
    <url>%2F2019%2F09%2F25%2FMy-favorite-Western-Porn-Stars%2F</url>
    <content type="text"><![CDATA[主要展示我认为颜值在线的porn stars,完全是个人审美~ AAbigaile Johnson Petty, Abigaile (karupspc.com), Abby, Abigail (putalocura.com), Abigaile (sapphicerotica.com), Spunky Bee (spunkybee.com), Gaile, Abigail Johnson, Abagaile Johnson (bangbros.com)1989-11-11 165cm 50kg 34B-23-35 捷克 2009-2017 Angela White Angie (Abby Winters)1985-03-04 157cm 59kg 32GG-28-38 澳大利亚 2003- BBailey Bae 1994-12-21 167cm 59kg 34B-24-34 美国 2014-2018 Bibi Jones Britney B., Britney Beth, Brittney Beth, Bibi Fox,Lexy Jones,Britney Grdina1991-07-23 168cm 50kg 34D-22-32 美国 2010-2013 Blaire Ivory Lena Anderson1998-01-28 185cm 68kg 34B-25-36 美国 2016- EEmma Mae Emma Ray, Emma May1991-09-19 173cm 60kg 34B-26-36 美国 2010-2016 Erica Ellyson 1984-10-01 165cm 42kg 35C-24-36 美国 2006-2011 GGloria Sol Gloria Sol, Penelope Y, Sofia, Dolores1995-05-12 155cm 50kg 34C-24-34 乌克兰 2016- HHaley Wilde Gia Demarco, Gia Dimarco, Haley Wilde1986-12-08 163cm 50kg 34DD-24-35 美国 2009- Hillary Scott 1983-02-03 160cm 43kg 34D-26-36 美国 2004—2011, 2016— JJenni Lee Jenny Lee, FTV Jenny, Stephanie Sadorra, Reese1982-02-11 160cm 48kg 34C-24-35 美国 KKarla Kush 1991-01-19 160cm 52kg 34B-24-36 美国 2013- Katarina Olendzskaia Katerina Olendzskaia, Katerina Olendzkaia E 俄罗斯 2010-2011 Kayden Kross Kayden, Jenna Nikol, Jenna Nickol, Kayden Cross1985-09-15 170cm 51kg 32D-22-34 俄罗斯 2010-2011 Krystal Boyd Anjelica Hanson, Abby, Angelica, Anjelica, Angelika, Abby C. (clubseventeen.com), Snejanna (amourangels.com), Katherine A. (met-art.com), Ebbi (nubiles.net), Abbiy (karupspc.com), Ira (hornythieftales.com), Krystal Boyd (fuckmyjeans.com), Ksyusha (cashforsextape.com) Kathy I. (femjoy.com), Slim Anya, Melanie1993-04-14 173cm 42kg 30B-23-32 俄罗斯 2011-2017 Kylie Page Bonnie Kinz, Bonnie1997-02-11 163cm 61kg 34G-25-35 美国 2016—— LLacie Heart Lacie Hart, Lacy Heart, Laci Heart, Lacey Heart, Laciie Hart1986-08-22 168cm 34B-27-34 美国 2005-2014 Lynna Nilsson Ms. Lynna, Miss Lynna (21 Sextury)1985-04-01 172cm 54kg 34C-25-37 瑞典 2015-2017 MMalena Morgan 1991-07-23 173cm 54kg 34C-25-34 美国 2011-2017 Mandy Kay 1995-01-14 157cm 52kg 32A-24-33 美国 2015- Melody Wylde Melody (ftvgirls.com), Melodywilde (twistysnetwork.com), SweetxMelody (cammodels.com)1997-11-10 163cm 48kg 32AA-24-36 日本 2017- Mila Azul Jane Y, Mia I, Mila, Milla, Milla Azul, Milla D, Milla Y, Mylen Branna, Mila Azil, Mila S1997-12-01 170cm 48kg 34D-23-33 乌克兰 2015- NNiki Lee Young Niki Young，Nikki Lee Young1985-10-15 163cm 53kg 34-24-36 美国 2011-2017 PPhoebe Queen Phoebe (digitaldesire.com,ftvgirls.com), Queen V (hotbody.com), Marry Jane (cam4.com)157cm 50kg 34C-25-35 美国 2011-2017 SSasha Foxxx Sasha Foxx(cam4.com)1990-02-22 152cm 49kg C-28- 美国 2013-2017 Sophie Moone Sophie Moon, Sophie Moore, Sophie Sweet, Sophie Weston, Sasha Saint, Tammi, Renata, Renee, Sofia Volkova, Reni, Rene, Sophia, Stella, Sandy, Sofie, Rene1981-12-24 165cm 50kg 32B-24-35 匈牙利 2000-2015]]></content>
      <categories>
        <category>停车场</category>
      </categories>
      <tags>
        <tag>adult</tag>
      </tags>
  </entry>
</search>
